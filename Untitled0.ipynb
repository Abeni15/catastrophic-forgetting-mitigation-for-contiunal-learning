{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PbKjtxSe6TgN",
        "outputId": "2a748543-0947-4812-b29f-8bab4bdb2ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "0.24.0+cu126\n"
          ]
        }
      ],
      "source": [
        "# In this cell I imported the pyTorch library and torchvision lib\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this cell loaded MNIST dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Transform: convert images to tensors\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load MNIST training dataset\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "#torchvision knows the offical download for MNIST and downloadtrue willexecuteit\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# DataLoader(grouping an shuffling the data)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Check one batch\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(labels[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69QW9NZw-WmO",
        "outputId": "dacb229b-e8f3-4495-b2b8-eb61eff5475c",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.03MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 131kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.29MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "tensor([0, 6, 0, 7, 3, 8, 4, 2, 2, 9])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(64 * 24 * 24, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "nSNXucStB3Tl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "\n",
        "test_images, _ = next(iter(train_loader))\n",
        "outputs = model(test_images)\n",
        "\n",
        "print(outputs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBqfnbU3CFB8",
        "outputId": "7ced1ec3-6571-45fc-e6f7-d3716eccbf9a",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = SimpleCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "11gCM3pp_q2M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(2):  # just 2 epochs for now\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()      # clear old gradients\n",
        "        outputs = model(images)    # forward pass\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()            # compute gradients\n",
        "        optimizer.step()           # update weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfvt9tQOHJ9X",
        "outputId": "6a25a4da-44f8-40a3-a01b-e7e6b4197038"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 126.6528\n",
            "Epoch 2, Loss: 37.3111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test dataset\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H20knCCuRf-k",
        "outputId": "a378c538-d4ae-4008-c700-8e9a27e1ef75"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fixed permutation (a random shuffle of 784 pixels)\n",
        "pixels = 28 * 28\n",
        "perm = torch.randperm(pixels)\n",
        "\n",
        "# Function to apply the permutation\n",
        "def permute_transform(tensor):\n",
        "    # Flatten image, shuffle pixels, then reshape back to 28x28\n",
        "    return tensor.view(-1, pixels)[:, perm].view(1, 28, 28)\n",
        "\n",
        "# Load the Task 2 (Scrambled) Dataset\n",
        "transform_task2 = transforms.Compose([transforms.ToTensor(), permute_transform])\n",
        "\n",
        "train_dataset2 = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform_task2)\n",
        "train_loader2 = DataLoader(train_dataset2, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset2 = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform_task2)\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"Task 2 (Permuted MNIST) is ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjX8XmAc0vWo",
        "outputId": "2ee64dee-a578-4738-8342-bca496b52257"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 2 (Permuted MNIST) is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the existing model on Task 2 for 2 epochs\n",
        "model.train()\n",
        "for epoch in range(2):\n",
        "    for images, labels in train_loader2:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Finished Task 2 Epoch {epoch+1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn8wB1At1LkI",
        "outputId": "7fde0e47-8fd6-4b4f-ab4a-ba5723dde642"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Task 2 Epoch 1\n",
            "Finished Task 2 Epoch 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "acc_task1 = get_accuracy(test_loader)  # Normal MNIST\n",
        "acc_task2 = get_accuracy(test_loader2) # Permuted MNIST\n",
        "\n",
        "print(f\"Accuracy on Task 1 (Original): {acc_task1:.2f}%\")\n",
        "print(f\"Accuracy on Task 2 (Scrambled): {acc_task2:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXgAUwO41O2O",
        "outputId": "c39e63dc-3a8a-4367-f470-a54d85c03aac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Task 1 (Original): 95.43%\n",
            "Accuracy on Task 2 (Scrambled): 97.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define which hardware to use (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        # 64 channels * 24 * 24 is the size after two convolutions\n",
        "        self.fc1 = nn.Linear(64 * 24 * 24, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Define the Loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFEYzsveUk6e",
        "outputId": "0a6090cd-95e2-4cc3-ffcc-97b97af85736"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- OPTIMIZED FAST REHEARSAL ---\n",
        "rehearsal_model = SimpleCNN().to(device)\n",
        "rehearsal_optimizer = torch.optim.Adam(rehearsal_model.parameters(), lr=0.001)\n",
        "\n",
        "# Get a \"Memory Buffer\" (reusable reminders of Task 1)\n",
        "# Make sure your train_dataset and train_loader2 are already loaded!\n",
        "mem_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
        "mem_images, mem_labels = next(iter(mem_loader))\n",
        "mem_images, mem_labels = mem_images.to(device), mem_labels.to(device)\n",
        "\n",
        "rehearsal_model.train()\n",
        "# Training on Task 2 while replaying Task 1\n",
        "for i, (images, labels) in enumerate(train_loader2):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    rehearsal_optimizer.zero_grad()\n",
        "\n",
        "    loss_new = criterion(rehearsal_model(images), labels)\n",
        "    loss_old = criterion(rehearsal_model(mem_images), mem_labels)\n",
        "\n",
        "    (loss_new + loss_old).backward()\n",
        "    rehearsal_optimizer.step()\n",
        "\n",
        "print(\"Rehearsal Training Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwPBm3eCUqqt",
        "outputId": "eee0a798-f25f-447d-e0fd-953ad72758e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rehearsal Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in loader:\n",
        "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += lbls.size(0)\n",
        "            correct += (predicted == lbls).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "acc1 = evaluate(rehearsal_model, test_loader)\n",
        "acc2 = evaluate(rehearsal_model, test_loader2)\n",
        "\n",
        "print(f\"Task 1 (Original) Accuracy: {acc1:.2f}%\")\n",
        "print(f\"Task 2 (Permuted) Accuracy: {acc2:.2f}%\")\n",
        "print(f\"Average Accuracy: {(acc1 + acc2)/2:.2f}%\")\n",
        "print(f\"Forgetting Measure: {98.6 - acc1:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS-50QyyUvQW",
        "outputId": "97403bf2-2bc6-4b04-ebd5-ed6682c478a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 (Original) Accuracy: 80.62%\n",
            "Task 2 (Permuted) Accuracy: 96.57%\n",
            "Average Accuracy: 88.59%\n",
            "Forgetting Measure: 17.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize a fresh model for this strategy\n",
        "reg_model = SimpleCNN().to(device)\n",
        "reg_optimizer = torch.optim.Adam(reg_model.parameters(), lr=0.001)\n",
        "\n",
        "# 2. Train on Task 1 (Standard MNIST)\n",
        "reg_model.train()\n",
        "for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    reg_optimizer.zero_grad()\n",
        "    loss = criterion(reg_model(images), labels)\n",
        "    loss.backward()\n",
        "    reg_optimizer.step()\n",
        "\n",
        "# 3. SAVE THE WEIGHTS (This is our \"anchor\" for the penalty)\n",
        "import copy\n",
        "task1_weights = {}\n",
        "for name, param in reg_model.named_parameters():\n",
        "    task1_weights[name] = param.data.clone()\n",
        "\n",
        "print(\"Task 1 finished and weights anchored!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M32hhNUUVKhO",
        "outputId": "5b9c6f8c-7ec9-48d1-b6b2-74fc2ed895e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 finished and weights anchored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How strong should the 'lock' be?\n",
        "importance_lambda = 0.5\n",
        "\n",
        "reg_model.train()\n",
        "for i, (images, labels) in enumerate(train_loader2):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    reg_optimizer.zero_grad()\n",
        "\n",
        "    # Standard Loss for Task 2\n",
        "    loss_new = criterion(reg_model(images), labels)\n",
        "\n",
        "    # Regularization Penalty:\n",
        "    # Compare current weights to Task 1 weights and penalize the difference\n",
        "    reg_loss = 0\n",
        "    for name, param in reg_model.named_parameters():\n",
        "        reg_loss += torch.sum((param - task1_weights[name]) ** 2)\n",
        "\n",
        "    # Total Loss = Learning New Task + Staying close to Old Weights\n",
        "    total_loss = loss_new + (importance_lambda * reg_loss)\n",
        "\n",
        "    total_loss.backward()\n",
        "    reg_optimizer.step()\n",
        "\n",
        "print(\"Regularization Training Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl0iwFjxVQpe",
        "outputId": "663eb72d-df7f-477d-aaf1-248c1ae8fe96"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_acc1 = evaluate(reg_model, test_loader)\n",
        "reg_acc2 = evaluate(reg_model, test_loader2)\n",
        "\n",
        "print(f\"--- Regularization Strategy Results ---\")\n",
        "print(f\"Task 1 (Original) Accuracy: {reg_acc1:.2f}%\")\n",
        "print(f\"Task 2 (Permuted) Accuracy: {reg_acc2:.2f}%\")\n",
        "print(f\"Average Accuracy: {(reg_acc1 + reg_acc2)/2:.2f}%\")\n",
        "print(f\"Forgetting Measure: {98.6 - reg_acc1:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEo9M2tAVYr_",
        "outputId": "82f11eab-739f-428b-cfe4-7ef809ee9bdc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Regularization Strategy Results ---\n",
            "Task 1 (Original) Accuracy: 91.43%\n",
            "Task 2 (Permuted) Accuracy: 46.93%\n",
            "Average Accuracy: 69.18%\n",
            "Forgetting Measure: 7.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save the Rehearsal Model (which had the best balance)\n",
        "torch.save(rehearsal_model.state_dict(), 'rehearsal_model.pth')\n",
        "\n",
        "# 2. Save the Regularization Model (which had the best forgetting score)\n",
        "torch.save(reg_model.state_dict(), 'regularization_model.pth')\n",
        "\n",
        "print(\"Success! Both models are saved in the Colab file folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAhEn3tFa15A",
        "outputId": "7e5a34df-5b4e-4e4b-c6ce-63069a1d0b0b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Both models are saved in the Colab file folder.\n"
          ]
        }
      ]
    }
  ]
}